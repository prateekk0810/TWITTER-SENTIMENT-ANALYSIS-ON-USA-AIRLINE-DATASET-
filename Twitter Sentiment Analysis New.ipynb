{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d18fbb96",
   "metadata": {},
   "source": [
    "# Importing the Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42e47d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk import pos_tag\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af65b6d2",
   "metadata": {},
   "source": [
    "# Preparing Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3dc098",
   "metadata": {},
   "source": [
    "# Importing Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b840826a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('twitter train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd0c3476",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[['text', 'airline_sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0062fab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = df_train.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2914f6",
   "metadata": {},
   "source": [
    "# Splitting the Tweet text into words using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83f244df",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_train = []\n",
    "for i in range(len(training_data)):\n",
    "    tweets_train.append([word_tokenize(training_data[i][0]), training_data[i][1]])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e580d4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cleaning the Words using WordNetLemmatizer available in NLTK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6aaf7ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = set(stopwords.words('english'))\n",
    "punctuations = list(string.punctuation)\n",
    "stops.update(punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f545e4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "def get_simple_pos(tag):\n",
    "    \n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64a14930",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def clean_tweets(words):\n",
    "    output_words = []\n",
    "    for w in words:\n",
    "        if w.isalpha():\n",
    "            if w.lower() not in stops:\n",
    "                pos = pos_tag([w])\n",
    "                clean_word = lemmatizer.lemmatize(w, pos = get_simple_pos(pos[0][1]))\n",
    "                output_words.append(clean_word.lower())\n",
    "    return output_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad6caf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tweets_train)):\n",
    "    tweets_train[i] = (clean_tweets(tweets_train[i][0]), tweets_train[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "355c67c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = []\n",
    "tweets = []\n",
    "for tweet, sentiment in tweets_train:\n",
    "    tweets.append(\" \".join(tweet))\n",
    "    y_train.append(sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8ee051",
   "metadata": {},
   "source": [
    "# Using Count Vectorizer to get the X Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa33f80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer(max_features=2000) # Tried using n grams but the accuracy was decreasing\n",
    "x_train_features = count_vec.fit_transform(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fb1e38",
   "metadata": {},
   "source": [
    "# Preparing Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54a191d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('twitter test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b87b6a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data = np.array(df_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d684229f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_test = []\n",
    "for t in testing_data:\n",
    "    t = clean_tweets(word_tokenize(t))\n",
    "    tweets_test.append(\" \".join(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc0586b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_features = count_vec.transform(tweets_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664af11b",
   "metadata": {},
   "source": [
    "# Performing Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31512fea",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4714936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC()\n",
    "svc.fit(x_train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "828406da",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm = svc.predict(x_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "561686f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(y_pred_svm)\n",
    "df.to_csv('predictions_svm.csv', index = False, header = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3d3b3e",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb23a6f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29588ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = rf.predict(x_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f58e9a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(y_pred_rf)\n",
    "df.to_csv('predictions_rf.csv', index = False, header = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4b0f29",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a01025d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnv = MultinomialNB(alpha = 1)\n",
    "mnv.fit(x_train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "801c37bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mnv = mnv.predict(x_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12d7cea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(y_pred_mnv)\n",
    "df.to_csv('predictions_mnv.csv', index = False, header = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad13b93f",
   "metadata": {},
   "source": [
    "# Descision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "249759ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = tree.DecisionTreeClassifier()\n",
    "dt.fit(x_train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b168a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dt = dt.predict(x_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8fbbf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(y_pred_dt)\n",
    "df.to_csv('predictions_dt.csv', index = False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7800fab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15078bef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa15ee3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ede4c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72703dfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8cc965",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
